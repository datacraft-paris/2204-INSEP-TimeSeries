{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0f478f-e887-4bfa-adc2-ccfe237a0d60",
   "metadata": {},
   "source": [
    "Chargement des paquets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35db4952-e9c7-4ddb-8788-b54eb27c24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "import dataframe_image as dfi\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.colors as clrs\n",
    "\n",
    "from sklearn import preprocessing #ajout du numéro \n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c61827-0302-4cad-9519-673a341e3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_t_start0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cb09b-b14e-48f3-b724-c98537048051",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19b155-5a06-4cd9-bc33-949cb9268cc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Chargement des jeux de données\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e39274-6ce9-48f3-893e-5f918c6e9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ath1 = pd.read_csv(\"../data/raw/bdd_ath1_vf.csv\")\n",
    "df_ath2 = pd.read_csv(\"../data/raw/bdd_ath2_vf.csv\")\n",
    "\n",
    "df_date_id_ath1 = pd.read_csv(\"../data/raw/dates_id_ath1_vf.csv\")\n",
    "df_date_id_ath2 = pd.read_csv(\"../data/raw/dates_id_ath2_vf.csv\")\n",
    "\n",
    "df_labels_ath1_vf = pd.read_csv(\"../data/raw/rpe_labels_ath1_vf.csv\")\n",
    "df_labels_ath2_vf = pd.read_csv(\"../data/raw/rpe_labels_ath2_vf.csv\")\n",
    "\n",
    "df_morning_ath1_vf = pd.read_csv(\"../data/raw/morning_ath1_vf.csv\")\n",
    "df_morning_ath2_vf = pd.read_csv(\"../data/raw/morning_ath2_vf.csv\")\n",
    "\n",
    "df_phases_ath1 = pd.read_csv(\"../data/raw/phases_ath1.csv\")\n",
    "df_phases_ath2 = pd.read_csv(\"../data/raw/phases_ath2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860c5530-2664-4b30-92ad-250b3a1ad05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athlete 1\n",
      "df_ath1.shape              (921334, 24)\n",
      "df_date_id_ath1.shape      (141, 3)\n",
      "df_labels_ath1_vf.shape    (142, 5)\n",
      "df_morning_ath1_vf.shape   (150, 15)\n",
      "df_phases_ath1.shape       (371, 5)\n",
      " \n",
      " ----------------------------------------- \n",
      " \n",
      "athlete 2\n",
      "df_ath2.shape              (767623, 24)\n",
      "df_date_id_ath2.shape      (129, 3)\n",
      "df_labels_ath2_vf.shape    (129, 5)\n",
      "df_morning_ath2_vf.shape   (20, 15)\n",
      "df_phases_ath2.shape       (97, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"athlete 1\")\n",
    "print(\"df_ath1.shape             \", df_ath1.shape)\n",
    "print(\"df_date_id_ath1.shape     \", df_date_id_ath1.shape)\n",
    "print(\"df_labels_ath1_vf.shape   \", df_labels_ath1_vf.shape)\n",
    "print(\"df_morning_ath1_vf.shape  \", df_morning_ath1_vf.shape)\n",
    "print(\"df_phases_ath1.shape      \", df_phases_ath1.shape)\n",
    "\n",
    "print(\" \\n ----------------------------------------- \\n \")\n",
    "\n",
    "print(\"athlete 2\")\n",
    "print(\"df_ath2.shape             \", df_ath2.shape)\n",
    "print(\"df_date_id_ath2.shape     \", df_date_id_ath2.shape)\n",
    "print(\"df_labels_ath2_vf.shape   \", df_labels_ath2_vf.shape)\n",
    "print(\"df_morning_ath2_vf.shape  \", df_morning_ath2_vf.shape)\n",
    "print(\"df_phases_ath2.shape      \", df_phases_ath2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b219b940-88ef-4a96-bf0c-281107b005b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2883982-665a-4679-bd11-3df05daea2eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Formatage des jeux de données\n",
    "\n",
    "Les dates sont initialement au format string dans les données. On les convertit en time objects de Python pour pouvoir les filtrer et jouer avec.  \n",
    "\n",
    "Ensuite on nettoie un peu les colonnes en supprimant celles qui ne servent à rien. (typiquement **Steps.per.Minute** et **Swim.Cadence**)  \n",
    "\n",
    "Puis on fait un encodage particulier pour numéroter par entiers croissants les jours d'entraînement d'une part et les types d'entraînement dans une même journée d'autre part. À un jour donné, pour un type d'entraînement, les points de mesure sont déjà numérotés par entiers croissants dans la colonne **tps** que l'on renommera également.  \n",
    "**Pour être clair**, le dataframe final comportera trois colonnes de valeurs entières:\n",
    "1. La première représente le nombre de jours d'entraînement dans la saison (e.g. 1 pour le premier entraînement, 120 pour le 120ème entraînement).\n",
    "1. La deuxième colonne représente le nombre d'entraînements dans la même journée ; elle est majoritairement valorisée à 1, mais il arrive qu'une athlète fasse au plus 4 types d'entraînement différents dans la même journée (e.g. échauffement, endurance, intensité et récupération).\n",
    "1. Et enfin, la dernière colonne représente le numéro du point de mesure au cours d'un entraînement donné ; cette valeur va 1 jusqu'à \\~10000 pour les entraînements les plus longs, elle est réinitialisée à 1 quand on change de type d'entraînement dans une même journée.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d60e8e2e-27d1-4d10-b100-ac2ee4ead55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_t_start1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c180a5-39e2-4696-ba04-653deb19ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to rearrange and sort both dataframes: 19.8934223651886\n"
     ]
    }
   ],
   "source": [
    "def df_create_right_timestamp(Date, Time):\n",
    "    return dt.datetime.combine(Date, Time)\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "df_ath1['Start.Time'] =  pd.to_datetime(df_ath1['Start.Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_ath1['date_only'] = df_ath1['Start.Time'].dt.date                                           #C> - Cette colonne ne sert à rien: contient seulement 4 dates\n",
    "df_ath1['time_only'] = df_ath1['Start.Time'].dt.time\n",
    "\n",
    "df_ath1['Date'] =  pd.to_datetime(df_ath1['Date'], format='%Y-%m-%d').dt.date\n",
    "df_phases_ath1['date'] = pd.to_datetime(df_phases_ath1['date'], format=\"%Y-%m-%d\").dt.date\n",
    "\n",
    "#C>-----\n",
    "\n",
    "df_ath2['Start.Time'] =  pd.to_datetime(df_ath2['Start.Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_ath2['date_only'] = df_ath2['Start.Time'].dt.date                                           #C> - Cette colonne ne sert à rien: contient seulement 4 dates\n",
    "df_ath2['time_only'] = df_ath2['Start.Time'].dt.time\n",
    "\n",
    "df_ath2['Date'] =  pd.to_datetime(df_ath2['Date'], format='%Y-%m-%d').dt.date\n",
    "df_phases_ath2['date'] = pd.to_datetime(df_phases_ath2['date'], format=\"%Y-%m-%d\").dt.date\n",
    "\n",
    "#C>-----\n",
    "\n",
    "df_ath1['Timestamp'] = df_ath1.apply(lambda row: df_create_right_timestamp(row[\"Date\"], row[\"time_only\"]), axis=1)\n",
    "df_ath2['Timestamp'] = df_ath2.apply(lambda row: df_create_right_timestamp(row[\"Date\"], row[\"time_only\"]), axis=1)\n",
    "\n",
    "df_ath1 = df_ath1.sort_values(['Timestamp'], ascending=[True])\n",
    "df_ath2 = df_ath2.sort_values(['Timestamp'], ascending=[True])\n",
    "# df_ath1 = df_ath1.sort_values(['Date', 'time_only'], ascending=[True, True])\n",
    "# df_ath2 = df_ath2.sort_values(['Date', 'time_only'], ascending=[True, True])\n",
    "print(f\"Time taken to rearrange and sort both dataframes: {time.time()-t_start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a4c9f6-cae4-4570-831a-7af45772519c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before merge: len(df_ath1) = 921334; len(df_ath2) = 767623\n",
      "After merge: len(df_ath1) = 928649; len(df_ath2) = 767623\n",
      "\n",
      "Time taken 0.743018627166748\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "print(f\"Before merge: len(df_ath1) = {len(df_ath1)}; len(df_ath2) = {len(df_ath2)}\")\n",
    "df_ath1 = pd.merge(df_ath1, df_labels_ath1_vf[['id','type']], on='id', how='left')\n",
    "df_phases_ath1.rename(columns = {'date':'Date'}, inplace = True)\n",
    "df_ath1 = pd.merge(df_ath1, df_phases_ath1[['Date','day_cycle', 'phase']], on='Date', how='left')\n",
    "\n",
    "df_ath2 = pd.merge(df_ath2, df_labels_ath2_vf[['id','type']], on='id', how='left')\n",
    "df_phases_ath2.rename(columns={\"date\": \"Date\"}, inplace = True)\n",
    "df_ath2 = pd.merge(df_ath2, df_phases_ath2[['Date','day_cycle', 'phase']], on='Date', how='left')\n",
    "print(f\"After merge: len(df_ath1) = {len(df_ath1)}; len(df_ath2) = {len(df_ath2)}\")\n",
    "\n",
    "print(f\"\\nTime taken {time.time()-t_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4572d013-d69b-49fc-bef5-03b0194c7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_ath1[\"Steps.per.Minute\"]\n",
    "del df_ath1[\"Swim.Cadence\"]\n",
    "del df_ath1[\"Start.Time\"]\n",
    "del df_ath1[\"date_only\"]\n",
    "del df_ath1[\"max_hr\"]\n",
    "\n",
    "del df_ath2[\"Steps.per.Minute\"]\n",
    "del df_ath2[\"Swim.Cadence\"]\n",
    "del df_ath2[\"Start.Time\"]\n",
    "del df_ath2[\"date_only\"]\n",
    "del df_ath2[\"max_hr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4c581-ffb2-401f-af25-b0f3fea7793f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Création des trois colonnes de valeurs entières pour le numéro des jours, le numéro des entraînements et le numéro des points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db239644-9cf7-449c-bdc5-2c17e2d3ff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 9.227909326553345\n"
     ]
    }
   ],
   "source": [
    "def encode_day_training_point(df_tmp):\n",
    "    list_of_dates = np.sort(df_tmp['Date'].unique())\n",
    "    list_dates_int = [(date, ctr, 1) for ctr, date in enumerate(list_of_dates, start=1)]\n",
    "    dict_dates_int = dict(zip(np.arange(0,120,1), list_dates_int))\n",
    "    df_dates_int = pd.DataFrame.from_dict(dict_dates_int, orient='index', columns=['Date', 'day_index', 'training_index'])\n",
    "\n",
    "    df_tmp = pd.merge(df_tmp, df_dates_int, on='Date', how='left')\n",
    "\n",
    "    for date in list_of_dates:\n",
    "        Series_tps = df_tmp[df_tmp['Date'] == date]['tps']\n",
    "        tps1_indices = Series_tps[Series_tps == 1].index\n",
    "    \n",
    "        if len(tps1_indices) == 2 :\n",
    "            idx_tps1 = tps1_indices[1]\n",
    "            idx_tps_max = Series_tps.loc[idx_tps1:].idxmax()\n",
    "            df_tmp.loc[idx_tps1:idx_tps_max, ['training_index']] = 2\n",
    "        \n",
    "        if len(tps1_indices) > 2 :\n",
    "            for i in range(1, len(tps1_indices)-1):\n",
    "                idx_tps1 = tps1_indices[i]\n",
    "                idx_tps_max = tps1_indices[i+1]-1\n",
    "                df_tmp.loc[idx_tps1:idx_tps_max, ['training_index']] = i+1\n",
    "            \n",
    "            idx_tps1 = idx_tps_max+1\n",
    "            idx_tps_max = Series_tps.loc[idx_tps1:].idxmax()\n",
    "            df_tmp.loc[idx_tps1:idx_tps_max, ['training_index']] = i+2\n",
    "\n",
    "    return df_tmp\n",
    "\n",
    "# %timeit encode_day_training_point(df_ath1)\n",
    "t_start = time.time()\n",
    "\n",
    "df_ath1 = encode_day_training_point(df_ath1)\n",
    "df_ath2 = encode_day_training_point(df_ath2)\n",
    "\n",
    "print(f\"Time taken {time.time()-t_start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47e465-8c23-42e3-bf77-2480fb9c8653",
   "metadata": {},
   "source": [
    "Ici, pour les types d'entraînement (endurance, intensité etc.) on remplace les nan, qui sont des float, par des chaînes de caractère 'nan'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df49d10-ca98-4320-a856-fb6e8999c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trainings(df_tmp, lower_threshold=np.timedelta64(30,'m')):\n",
    "    df_tmp = df_tmp.sort_values(['Timestamp'], ascending=[True])\n",
    "\n",
    "    time_delta = df_tmp['Timestamp'].diff()\n",
    "    date_delta = df_tmp['Date'].diff()\n",
    "\n",
    "    list_index_breaks = df_tmp[(time_delta > lower_threshold) & (date_delta < one_day)].index.tolist()\n",
    "    print(f\"Number of times there are no data for more than {lower_threshold}: {len(list_index_breaks)}\")\n",
    "\n",
    "    for idx in list_index_breaks :\n",
    "        date_ncur, date_nbef = df_tmp.loc[idx, \"Date\"], df_tmp.loc[idx-1, \"Date\"]\n",
    "        if date_ncur == date_nbef :\n",
    "            train_idx_ncur, train_idx_nbef = df_tmp.loc[idx, \"training_index\"], df_tmp.loc[idx-1, \"training_index\"] \n",
    "            tps_ncur, tps_nbef = df_tmp.loc[idx, \"tps\"], df_tmp.loc[idx-1, \"tps\"]\n",
    "\n",
    "            if train_idx_ncur == train_idx_nbef+1 :\n",
    "                print(f\"On date {date_ncur}, already two distinct trainings with time-delta > {lower_threshold} ({df_tmp.loc[idx-1, 'type']}:{train_idx_nbef}, {df_tmp.loc[idx, 'type']}:{train_idx_ncur}) \\n\")\n",
    "\n",
    "            elif train_idx_ncur == train_idx_nbef and tps_ncur == tps_nbef+1 :\n",
    "                print(df_tmp.loc[idx-1, [\"Timestamp\", \"Date\", \"time_only\", \"training_index\", \"tps\", \"type\"]].tolist())\n",
    "                print(df_tmp.loc[idx, [\"Timestamp\", \"Date\", \"time_only\", \"training_index\", \"tps\", \"type\"]].tolist())\n",
    "                print(\" \")\n",
    "                df_loc = df_tmp.iloc[idx:]\n",
    "                df_loc = df_loc[df_loc[\"Date\"] == date_ncur]\n",
    "                \n",
    "                if len(df_loc[\"training_index\"].unique()) == 1:\n",
    "                    idx_max = df_loc['tps'].idxmax()\n",
    "\n",
    "                    df_tmp.loc[idx:idx_max, 'tps'] = np.arange(1, idx_max-idx+2, 1)\n",
    "                    df_tmp.loc[idx:idx_max, 'training_index'] = train_idx_nbef+1\n",
    "\n",
    "                else :\n",
    "                    for ctr, group in enumerate(df_loc.groupby('training_index'), start=1):\n",
    "                        idx_min, idx_max = group[1]['tps'].idxmin(), group[1]['tps'].idxmax()\n",
    "                        df_tmp.loc[idx_min:idx_max, 'training_index'] = group[0]+1\n",
    "\n",
    "            else :\n",
    "                print(\"Something you haven't thought of.\")\n",
    "                print(df_tmp.loc[idx-1, [\"Timestamp\", \"Date\", \"time_only\", \"training_index\", \"tps\", \"type\"]].tolist())\n",
    "                print(df_tmp.loc[idx, [\"Timestamp\", \"Date\", \"time_only\", \"training_index\", \"tps\", \"type\"]].tolist())\n",
    "                print(\" \")\n",
    "\n",
    "        else :\n",
    "            print(\"Nothing...\", df_tmp.loc[idx, \"Date\"], df_tmp.loc[idx-1, \"Date\"])\n",
    "\n",
    "    print(\" \")\n",
    "\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8679a27f-59c0-4cda-bf94-e02562960379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athlète 1:\n",
      "Number of times there are no data for more than 30 minutes: 8\n",
      "[Timestamp('2021-05-03 17:24:05'), datetime.date(2021, 5, 3), datetime.time(17, 24, 5), 1, 1007, 'endurance']\n",
      "[Timestamp('2021-05-03 17:57:35'), datetime.date(2021, 5, 3), datetime.time(17, 57, 35), 1, 1008, 'endurance']\n",
      " \n",
      "On date 2021-05-15, already two distinct trainings with time-delta > 30 minutes (endurance:1, endurance:2) \n",
      "\n",
      "[Timestamp('2021-06-05 15:08:11'), datetime.date(2021, 6, 5), datetime.time(15, 8, 11), 1, 2748, 'intensity']\n",
      "[Timestamp('2021-06-05 16:03:07'), datetime.date(2021, 6, 5), datetime.time(16, 3, 7), 1, 2749, 'intensity']\n",
      " \n",
      "[Timestamp('2021-06-11 17:59:53'), datetime.date(2021, 6, 11), datetime.time(17, 59, 53), 1, 1002, 'intensity']\n",
      "[Timestamp('2021-06-11 18:37:50'), datetime.date(2021, 6, 11), datetime.time(18, 37, 50), 1, 1003, 'intensity']\n",
      " \n",
      "On date 2021-06-30, already two distinct trainings with time-delta > 30 minutes (test:1, endurance:2) \n",
      "\n",
      "[Timestamp('2021-07-30 15:00:33'), datetime.date(2021, 7, 30), datetime.time(15, 0, 33), 1, 289, 'endurance']\n",
      "[Timestamp('2021-07-30 15:34:10'), datetime.date(2021, 7, 30), datetime.time(15, 34, 10), 1, 290, 'endurance']\n",
      " \n",
      "On date 2021-07-31, already two distinct trainings with time-delta > 30 minutes (race:2, recovery:3) \n",
      "\n",
      "[Timestamp('2021-08-20 13:05:15'), datetime.date(2021, 8, 20), datetime.time(13, 5, 15), 1, 12323, 'endurance']\n",
      "[Timestamp('2021-08-20 13:36:13'), datetime.date(2021, 8, 20), datetime.time(13, 36, 13), 1, 12324, 'endurance']\n",
      " \n",
      " \n",
      "------------------------\n",
      "Athlète 2:\n",
      "Number of times there are no data for more than 30 minutes: 14\n",
      "[Timestamp('2021-04-06 14:59:03'), datetime.date(2021, 4, 6), datetime.time(14, 59, 3), 1, 153, 'track']\n",
      "[Timestamp('2021-04-06 16:37:05'), datetime.date(2021, 4, 6), datetime.time(16, 37, 5), 1, 154, 'track']\n",
      " \n",
      "[Timestamp('2021-04-08 16:47:18'), datetime.date(2021, 4, 8), datetime.time(16, 47, 18), 2, 156, 'track']\n",
      "[Timestamp('2021-04-08 18:00:07'), datetime.date(2021, 4, 8), datetime.time(18, 0, 7), 2, 157, 'track']\n",
      " \n",
      "[Timestamp('2021-04-21 14:47:38'), datetime.date(2021, 4, 21), datetime.time(14, 47, 38), 1, 260, 'track']\n",
      "[Timestamp('2021-04-21 15:19:13'), datetime.date(2021, 4, 21), datetime.time(15, 19, 13), 1, 261, 'track']\n",
      " \n",
      "On date 2021-04-21, already two distinct trainings with time-delta > 30 minutes (track:2, track:3) \n",
      "\n",
      "On date 2021-04-30, already two distinct trainings with time-delta > 30 minutes (warmup:1, intensity:2) \n",
      "\n",
      "On date 2021-05-10, already two distinct trainings with time-delta > 30 minutes (endurance:1, endurance:2) \n",
      "\n",
      "On date 2021-06-03, already two distinct trainings with time-delta > 30 minutes (warmup:1, intensity:2) \n",
      "\n",
      "On date 2021-06-05, already two distinct trainings with time-delta > 30 minutes (warmup:1, intensity:2) \n",
      "\n",
      "[Timestamp('2021-06-13 12:27:35'), datetime.date(2021, 6, 13), datetime.time(12, 27, 35), 1, 626, 'warmup']\n",
      "[Timestamp('2021-06-13 13:10:56'), datetime.date(2021, 6, 13), datetime.time(13, 10, 56), 1, 627, 'warmup']\n",
      " \n",
      "[Timestamp('2021-06-13 13:42:47'), datetime.date(2021, 6, 13), datetime.time(13, 42, 47), 2, 1912, 'warmup']\n",
      "[Timestamp('2021-06-13 14:15:11'), datetime.date(2021, 6, 13), datetime.time(14, 15, 11), 2, 1913, 'warmup']\n",
      " \n",
      "[Timestamp('2021-06-13 14:33:02'), datetime.date(2021, 6, 13), datetime.time(14, 33, 2), 3, 1072, 'warmup']\n",
      "[Timestamp('2021-06-13 15:14:20'), datetime.date(2021, 6, 13), datetime.time(15, 14, 20), 3, 1073, 'warmup']\n",
      " \n",
      "On date 2021-06-17, already two distinct trainings with time-delta > 30 minutes (warmup:1, warmup:2) \n",
      "\n",
      "On date 2021-07-18, already two distinct trainings with time-delta > 30 minutes (endurance:1, endurance:2) \n",
      "\n",
      "On date 2021-09-14, already two distinct trainings with time-delta > 30 minutes (endurance:1, intensity:2) \n",
      "\n",
      " \n",
      "Time taken: 2.3041622638702393\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "one_second, thirty_minute, one_day = np.timedelta64(1,'s'), np.timedelta64(30,'m'), np.timedelta64(1, 'D')\n",
    "\n",
    "print(\"Athlète 1:\")\n",
    "df_ath1 = split_trainings(df_ath1, lower_threshold=thirty_minute)\n",
    "print(\"------------------------\\nAthlète 2:\")\n",
    "df_ath2 = split_trainings(df_ath2, lower_threshold=thirty_minute)\n",
    "\n",
    "print(f\"Time taken: {time.time()-t_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ffd94c-f0f0-4df8-bbe9-4c9c6b296299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.1137769222259521\n"
     ]
    }
   ],
   "source": [
    "def create_training_counter(df_tmp):\n",
    "    ctr = 0\n",
    "    listou = []\n",
    "    for date, d1 in df_tmp.groupby(\"Date\"):\n",
    "        for training_idx, d2 in d1.groupby(\"training_index\"):\n",
    "            ctr += 1\n",
    "            listou.append({\"Date\":date, \"training_index\":training_idx, \"training_counter\":ctr})\n",
    "    small_df = pd.DataFrame(listou)\n",
    "\n",
    "    return df_tmp.merge(small_df, how='left', on=[\"Date\",\"training_index\"])\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "df_ath1 = create_training_counter(df_ath1)\n",
    "df_ath2 = create_training_counter(df_ath2)\n",
    "\n",
    "print(f\"Time taken: {time.time()-t_start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ce206-4935-4547-8702-9ecbcb1fd018",
   "metadata": {},
   "source": [
    "# On renomme les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d11987d-73b3-430f-8cdb-c7efedf31f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "df_ath1 = df_ath1.rename(columns={'Duree':'duree','Date': 'date', 'type': 'type_ent','Activite':'activite','Heart.Rate':'heart_rate','Power..Watts.':'power_watts',\n",
    "                             'Speed..meters.per.sec.':'speed_meters_per_sec','Bike.Cadence':\"bike_cadence\",'Total.Distance..meters.':'distance_cumul',\n",
    "                             'Latitude.in.Degree':'latitude','Longitude.in.Degree':'longitude','Elevation..meters.':'altitude',\n",
    "                             'Air.Temperature..celsius.':'temperature','Kcal':\"kcal_cst\",\"Distance\":\"dist_totale_cst\"})\n",
    "\n",
    "df_ath2 = df_ath2.rename(columns={'Duree':'duree','Date': 'date', 'type': 'type_ent','Activite':'activite','Heart.Rate':'heart_rate','Power..Watts.':'power_watts',\n",
    "                             'Speed..meters.per.sec.':'speed_meters_per_sec','Bike.Cadence':\"bike_cadence\",'Total.Distance..meters.':'distance_cumul',\n",
    "                             'Latitude.in.Degree':'latitude','Longitude.in.Degree':'longitude','Elevation..meters.':'altitude',\n",
    "                             'Air.Temperature..celsius.':'temperature','Kcal':\"kcal_cst\",\"Distance\":\"dist_totale_cst\"})\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19311b-28a4-4767-a698-a42daf8909a9",
   "metadata": {},
   "source": [
    "# On réordonne les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34afbccf-4151-4e28-9ef3-548b5760da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['Timestamp', 'date', 'time_only', 'training_counter', 'day_index', 'training_index', 'tps', 'type_ent', 'day_cycle', 'phase', 'activite',\n",
    "            'latitude', 'longitude', 'altitude', 'temperature', 'heart_rate', 'speed_meters_per_sec', 'power_watts', 'bike_cadence', 'distance_cumul',\n",
    "            'duree', 'kcal_cst', 'id', 'dist_totale_cst', 'mean_power', 'max_power', 'mean_hr', 'name']\n",
    "\n",
    "df_ath1 = df_ath1[col_list]\n",
    "df_ath2 = df_ath2[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc7559a-c0fb-4e00-adcf-7f01bb5d6b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athlete 1: # colonnes 28 - colonnes ['Timestamp', 'date', 'time_only', 'training_counter', 'day_index', 'training_index', 'tps', 'type_ent', 'day_cycle', 'phase', 'activite', 'latitude', 'longitude', 'altitude', 'temperature', 'heart_rate', 'speed_meters_per_sec', 'power_watts', 'bike_cadence', 'distance_cumul', 'duree', 'kcal_cst', 'id', 'dist_totale_cst', 'mean_power', 'max_power', 'mean_hr', 'name']\n",
      " ----------------------------------------- \n",
      "Athlete 2: # colonnes 28 - colonnes ['Timestamp', 'date', 'time_only', 'training_counter', 'day_index', 'training_index', 'tps', 'type_ent', 'day_cycle', 'phase', 'activite', 'latitude', 'longitude', 'altitude', 'temperature', 'heart_rate', 'speed_meters_per_sec', 'power_watts', 'bike_cadence', 'distance_cumul', 'duree', 'kcal_cst', 'id', 'dist_totale_cst', 'mean_power', 'max_power', 'mean_hr', 'name']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Athlete 1: # colonnes {len(df_ath1.columns)} - colonnes {df_ath1.columns.tolist()}\")\n",
    "print(\" ----------------------------------------- \")\n",
    "print(f\"Athlete 2: # colonnes {len(df_ath2.columns)} - colonnes {df_ath2.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bd97b-0918-4216-acf8-7f1809a968b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfdbd8-5302-47c4-bbb5-cd0fae023ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "759e5ffa-5700-4b4e-8b8e-65f72b0b1285",
   "metadata": {},
   "source": [
    "## On remplit les trous dans les séries temporelle du même entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5788410b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resampling(df): #fonction qui bouche les trous \n",
    "    df['add_tps']=0\n",
    "    df_fin = pd.DataFrame()\n",
    "    for day, d1 in df.groupby('day_index'):\n",
    "        for training, d2 in d1.groupby('training_index'):\n",
    "            timestamp_start = min(d2.Timestamp)\n",
    "            timestamp_end = max(d2.Timestamp)\n",
    "            diff=timestamp_end-timestamp_start\n",
    "            longueur_trou = int(diff / dt.timedelta(seconds=1))\n",
    "            list_timestamp = [timestamp_start+dt.timedelta(seconds=n) for n in range(longueur_trou+1)]\n",
    "            list_tps=[tps+1 for tps in range(longueur_trou+1)]\n",
    "            \n",
    "            df_add = pd.DataFrame(list(zip(list_timestamp,list_tps)),columns=['Timestamp','tps'])\n",
    "            \n",
    "            df_add['date']=d2['date'].iloc[0]\n",
    "            df_add['training_counter']=d2['training_counter'].iloc[0]\n",
    "            df_add['day_index'] = day\n",
    "            df_add['training_index'] = training\n",
    "            df_add['type_ent']=d2['type_ent'].iloc[0]\n",
    "\n",
    "            df_add['day_cycle']=d2['day_cycle'].iloc[0]\n",
    "            df_add['phase']=d2['phase'].iloc[0]\n",
    "            df_add['activite']=d2['activite'].iloc[0]\n",
    "\n",
    "            df_add['duree']=d2['duree'].iloc[0]\n",
    "            df_add['kcal_cst']=d2['kcal_cst'].iloc[0]\n",
    "            df_add['id']=d2['id'].iloc[0]\n",
    "            df_add['dist_totale_cst']=d2['dist_totale_cst'].iloc[0]\n",
    "            df_add['mean_power']=d2['mean_power'].iloc[0]\n",
    "            df_add['max_power']=d2['max_power'].iloc[0]\n",
    "            df_add['mean_hr']=d2['mean_hr'].iloc[0]\n",
    "            df_add['name']=d2['name'].iloc[0]\n",
    "            \n",
    "            df_fin = pd.concat([df_fin,df_add])\n",
    "            \n",
    "    df_fin.reset_index(drop=True,inplace=True)\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "\n",
    "    df_final = df_fin.merge(df[['Timestamp', 'latitude', 'longitude', 'altitude', 'temperature',\n",
    "                                'heart_rate', 'speed_meters_per_sec', 'power_watts', 'bike_cadence',\n",
    "                                'distance_cumul', 'add_tps']], on='Timestamp',how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "    df[df['add_tps']!=0]=1\n",
    "    return df_final\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e05448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 17.934672355651855\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "df_ath1_full_date = resampling(df_ath1)\n",
    "df_ath2_full_date = resampling(df_ath2)\n",
    "\n",
    "print(f\"Time taken: {time.time()-t_start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf0f9c6-5f8c-4d62-9fbe-2088bae783db",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca16030-9b50-42da-9063-1a38575feb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ath1_full_date.to_pickle(\"../data/formatted/df_ath1_full.pkl\")\n",
    "df_ath2_full_date.to_pickle(\"../data/formatted/df_ath2_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9129f-ccb0-4bf4-a246-56675c865462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c241c-7f76-49f3-9bc7-24d82c5882de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f4a507d-36c5-4770-a756-e2003e68cbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to format the data: 56.05195641517639\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total time taken to format the data: {time.time()-big_t_start0}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
